{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc9864b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, datetime\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b9e5d",
   "metadata": {},
   "source": [
    "- create loop to iterate through 15 minute time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a573d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"http://data.gdeltproject.org/gdeltv2/\" # first part of gdelt data link\n",
    "url_2 = \"20210101000000\" # date time \n",
    "url_3 = \".gkg.csv.zip\" # file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01da08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.to_datetime(int(url_2), format='%Y%m%d%H%M%S') + datetime.timedelta(minutes = 15) # test adding 15 mins to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09574164",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() # get current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url=\"http://data.gdeltproject.org/gdeltv2/20220119023000.gkg.csv.zip\"\n",
    "url = url_1 + url_2 + url_3 # combine URL parts\n",
    "sample_df=pd.read_csv(url, sep=\"\\t\", header=None, on_bad_lines=\"warn\") # read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79500405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_df.head() # display data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f08581",
   "metadata": {},
   "source": [
    "# Gather and Append 2021 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd05ec5",
   "metadata": {},
   "source": [
    "- create a function that reads in 2021 data and appends it to a master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master():\n",
    "    url_1 = \"http://data.gdeltproject.org/gdeltv2/\" # first part of gdelt data link\n",
    "    url_2 = \"20210116000000\" # date time \n",
    "    url_3 = \".gkg.csv.zip\" # file type\n",
    "    url = url_1 + url_2 + url_3 # combine URL parts\n",
    "    aggregate_df = pd.read_csv(url, sep=\"\\t\", header=None, on_bad_lines=\"warn\", encoding= 'unicode_escape') # read in data\n",
    "    current_time = pd.to_datetime(int(\"20210201000000\"), format='%Y%m%d%H%M%S') #datetime.datetime.now() # get current time\n",
    "    date_time = pd.to_datetime(int(url_2), format='%Y%m%d%H%M%S') # convert int to datetime\n",
    "    \n",
    "    while date_time <= current_time:\n",
    "        date_time += datetime.timedelta(minutes = 15) # test adding 15 mins to timestamp\n",
    "        url_2 = date_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        url = url_1 + url_2 + url_3 # combine URL parts\n",
    "        print(url)\n",
    "        new_df = pd.read_csv(url, sep=\"\\t\", header=None, on_bad_lines=\"warn\", encoding= 'unicode_escape') # read in data\n",
    "        aggregate_df = aggregate_df.append(new_df)\n",
    "    \n",
    "    return aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://data.gdeltproject.org/gdeltv2/20210116000000.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8599375",
   "metadata": {},
   "source": [
    "- 20210105104500: no encoding \n",
    "- 20210106074500: no encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('http://data.gdeltproject.org/gdeltv2/20210106074500.gkg.csv.zip', sep=\"\\t\", header=None, on_bad_lines=\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "agg_df = create_master()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Downloaded and appended in {(toc - tic)/60:0.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc50338",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "url_1 = \"http://data.gdeltproject.org/gdeltv2/\" # first part of gdelt data link\n",
    "url_2 = \"20210101000000\" # date time \n",
    "url_3 = \".gkg.csv.zip\" # file type\n",
    "current_time = pd.to_datetime(int(\"20210102000000\"), format='%Y%m%d%H%M%S')\n",
    "date_time = pd.to_datetime(int(url_2), format='%Y%m%d%H%M%S')\n",
    "url = url_1 + url_2 + url_3 # combine URL parts\n",
    "all_files.append(url)\n",
    "\n",
    "while date_time <= current_time:\n",
    "        date_time += datetime.timedelta(minutes = 15) # test adding 15 mins to timestamp\n",
    "        url_2 = date_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        url = url_1 + url_2 + url_3 # combine URL parts\n",
    "        all_files.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "#######\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header=None, on_bad_lines=\"warn\", encoding= 'unicode_escape')\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "#######\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Downloaded and appended in {(toc - tic)/60:0.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ea324",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6876b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5349cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(start, end):\n",
    "    all_files = []\n",
    "    url_1 = \"http://data.gdeltproject.org/gdeltv2/\" # first part of gdelt data link\n",
    "    url_3 = \".gkg.csv.zip\" # file type\n",
    "    current_time = pd.to_datetime(int(end), format='%Y%m%d%H%M%S')\n",
    "    date_time = pd.to_datetime(int(start), format='%Y%m%d%H%M%S')\n",
    "\n",
    "    while date_time <= current_time:\n",
    "        url_2 = date_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        url = url_1 + url_2 + url_3 # combine URL parts\n",
    "        all_files.append(url)\n",
    "        date_time += datetime.timedelta(minutes = 15) # test adding 15 mins to timestamp\n",
    "        \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f427666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_files(file_list):\n",
    "    # blank list for files\n",
    "    list_df = []\n",
    "    \n",
    "    # loop through all file names and load\n",
    "    for filename in file_list:\n",
    "        df = pd.read_csv(filename, sep=\"\\t\", header=None, on_bad_lines=\"warn\", encoding= 'unicode_escape')\n",
    "        list_df.append(df)\n",
    "    \n",
    "    # combine list of dataframes\n",
    "    frame = pd.concat(list_df, axis=0, ignore_index=True)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = get_file_list(\"20210101000000\", \"20210101001500\")\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_all_files(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(processes=core_count) as pool:\n",
    "    df1= pool.map(load_all_files, all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_count = mp.cpu_count()\n",
    "all_files = get_file_list(\"20210101000000\", \"20210101001500\")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "#######\n",
    "\n",
    "with mp.Pool(processes=core_count) as pool:\n",
    "    df1= pool.map(load_all_files, all_files)\n",
    "    \n",
    "#######\n",
    "toc = time.perf_counter()\n",
    "print(f\"Downloaded and appended in {(toc - tic)/60:0.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0814374",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "#######\n",
    "\n",
    "pool = mp.Pool(core_count)\n",
    "\n",
    "df2 = pool.map(load_all_files, all_files) # data is the list\n",
    "\n",
    "pool.close()\n",
    "    \n",
    "#######\n",
    "toc = time.perf_counter()\n",
    "print(f\"Downloaded and appended in {(toc - tic)/60:0.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(core_count)\n",
    "\n",
    "df2 = pool.map(load_all_files, all_files) # data is the list\n",
    "\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
