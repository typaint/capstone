{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8ad6d0",
   "metadata": {
    "id": "ef8ad6d0",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\">Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\">Load Data</a></span></li><li><span><a href=\"#Filter-Data\" data-toc-modified-id=\"Filter-Data-1.2\">Filter Data</a></span></li></ul></li><li><span><a href=\"#Readability\" data-toc-modified-id=\"Readability-2\">Readability</a></span></li><li><span><a href=\"#Tag-Articles\" data-toc-modified-id=\"Tag-Articles-3\">Tag Articles</a></span></li><li><span><a href=\"#NLP\" data-toc-modified-id=\"NLP-4\">NLP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Roberta-Pipeline\" data-toc-modified-id=\"Load-Roberta-Pipeline-4.1\">Load Roberta Pipeline</a></span></li><li><span><a href=\"#Summary-Stats\" data-toc-modified-id=\"Summary-Stats-4.2\">Summary Stats</a></span></li><li><span><a href=\"#Yahoo\" data-toc-modified-id=\"Yahoo-4.3\">Yahoo</a></span></li><li><span><a href=\"#MarketWatch\" data-toc-modified-id=\"MarketWatch-4.4\">MarketWatch</a></span></li><li><span><a href=\"#PR-Newswire\" data-toc-modified-id=\"PR-Newswire-4.5\">PR Newswire</a></span></li></ul></li><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-5\">Example</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0684c3b",
   "metadata": {
    "id": "f0684c3b"
   },
   "source": [
    "- git lfs install\n",
    "- git clone https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "VgEwrmRi9R9v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4014,
     "status": "ok",
     "timestamp": 1646867647468,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "VgEwrmRi9R9v",
    "outputId": "ba559454-8870-4081-9e08-dea20c2fe29e"
   },
   "outputs": [],
   "source": [
    "# !git lfs install\n",
    "# !git clone https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bq54txr8zqn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1026,
     "status": "ok",
     "timestamp": 1646867648477,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "1bq54txr8zqn",
    "outputId": "45e772fa-608f-4a7d-e970-9a950ac76cc7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "import os\n",
    "# cur_path = \"/content/drive/MyDrive/Colab Notebooks/capstone/\"\n",
    "# os.chdir(cur_path)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c4037f",
   "metadata": {
    "executionInfo": {
     "elapsed": 15544,
     "status": "ok",
     "timestamp": 1646867663988,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "00c4037f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62849f6",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa088ab",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d728f676",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1646867663991,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "d728f676"
   },
   "outputs": [],
   "source": [
    "def load_data(): \n",
    "    path = r'/Users/TyPainter1/Desktop/Masters/spring-2022/capstone/00-data/gdelt_data/'\n",
    "    #path = r'/content/drive/MyDrive/Colab Notebooks/capstone/gdelt_data/'\n",
    "    years = os.listdir(path)\n",
    "    years.remove('.DS_Store')\n",
    "    years.remove('.ipynb_checkpoints')\n",
    "    yr = [x for x in years if not (x.startswith('.'))]\n",
    "\n",
    "    year_paths= []\n",
    "    months=[]\n",
    "    file_paths= []\n",
    "\n",
    "    for i in range(len(years)): # enter year folder\n",
    "        year_paths.append(path + years[i]) # year paths\n",
    "        months.extend(os.listdir(year_paths[i])) # months of data in each year\n",
    "    months = [x for x in months if not (x.startswith('.'))]\n",
    "    for j in range(len(months)): # enter months in each year folder\n",
    "        file_paths.append(year_paths[i] + \"/\" + months[j]) # file in year path\n",
    "    \n",
    "    return(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9701eb",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7b3071",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1646867663992,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "ca7b3071"
   },
   "outputs": [],
   "source": [
    "def filter_websites(file):\n",
    "    df = pd.read_csv(file, index_col=[0]) # read in csv\n",
    "    m_df = df[df.website=='marketwatch.com'] # filter for website\n",
    "    p_df = df[df.website=='prnewswire.com'] # filter for website\n",
    "    y_df = df[df.website=='yahoo.com'][0:10] # filter for website\n",
    "    \n",
    "    return(m_df, p_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b206d2",
   "metadata": {},
   "source": [
    "## Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4193df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !pip install https://github.com/andreasvc/readability/tarball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b87701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbd62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grades(article):\n",
    "    if article == \"NA\":\n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['readability grades'])\n",
    "        vals = np.empty((1,9))\n",
    "        vals[:] = np.nan\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    elif article == \"\":\n",
    "        article = \"NA\"\n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['readability grades'])\n",
    "        vals = np.empty((1,9))\n",
    "        vals[:] = np.nan\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    else: \n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['readability grades'])\n",
    "        vals = list(results['readability grades'].values())\n",
    "        vals =[[round(val,2)] for val in vals]\n",
    "        vals = np.asarray(vals).T\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982c1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_info(article):\n",
    "    if article == \"NA\":\n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['sentence info'])\n",
    "        idx = [7,-2]\n",
    "        cols = [cols[i] for i in idx]\n",
    "        vals = np.empty((1,2))\n",
    "        vals[:] = np.nan\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    elif article == \"\":\n",
    "        article = \"NA\"\n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['sentence info'])\n",
    "        idx = [7,-2]\n",
    "        cols = [cols[i] for i in idx]\n",
    "        vals = np.empty((1,2))\n",
    "        vals[:] = np.nan\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    else:\n",
    "        results = readability.getmeasures(article, lang='en')\n",
    "        cols = list(results['sentence info'])\n",
    "        idx = [7,-2]\n",
    "        cols = [cols[i] for i in idx]\n",
    "        vals = list(results['sentence info'].values())\n",
    "        vals = [[vals[i]] for i in idx]\n",
    "        vals = np.asarray(vals).T\n",
    "        scores = pd.DataFrame(data=vals,columns=cols)\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a54390",
   "metadata": {},
   "source": [
    "## Tag Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13b9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fuzzywuzzy[speedup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2896f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fca411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>Abiomed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol     Security\n",
       "0    MMM           3M\n",
       "1    AOS  A. O. Smith\n",
       "2    ABT       Abbott\n",
       "3   ABBV       AbbVie\n",
       "4   ABMD      Abiomed"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick_comp_df = pd.read_csv(\"../00-data/company_tickers.csv\")\n",
    "tick_comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4484a249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3M',\n",
       " 'A. O. Smith',\n",
       " 'Abbott',\n",
       " 'AbbVie',\n",
       " 'Abiomed',\n",
       " 'Accenture',\n",
       " 'Activision Blizzard',\n",
       " 'ADM',\n",
       " 'Adobe',\n",
       " 'ADP',\n",
       " 'Advance Auto Parts',\n",
       " 'AES',\n",
       " 'Aflac',\n",
       " 'Agilent Technologies',\n",
       " 'AIG',\n",
       " 'Air Products',\n",
       " 'Akamai',\n",
       " 'Alaska Air Group',\n",
       " 'Albemarle',\n",
       " 'Alexandria',\n",
       " 'Align',\n",
       " 'Allegion',\n",
       " 'Alliant Energy',\n",
       " 'Allstate',\n",
       " 'Alphabet (Class A)',\n",
       " 'Alphabet (Class C)',\n",
       " 'Altria',\n",
       " 'Amazon',\n",
       " 'Amcor',\n",
       " 'AMD',\n",
       " 'Ameren',\n",
       " 'American Airlines Group',\n",
       " 'American Electric Power',\n",
       " 'American Express',\n",
       " 'American Tower',\n",
       " 'American Water',\n",
       " 'Ameriprise Financial',\n",
       " 'AmerisourceBergen',\n",
       " 'Ametek',\n",
       " 'Amgen',\n",
       " 'Amphenol',\n",
       " 'Analog Devices',\n",
       " 'Ansys',\n",
       " 'Anthem',\n",
       " 'Aon',\n",
       " 'APA Corporation',\n",
       " 'Apple',\n",
       " 'Applied Materials',\n",
       " 'Aptiv',\n",
       " 'Arista',\n",
       " 'Assurant',\n",
       " 'AT&T',\n",
       " 'Atmos Energy',\n",
       " 'Autodesk',\n",
       " 'AutoZone',\n",
       " 'AvalonBay Communities',\n",
       " 'Avery Dennison',\n",
       " 'Baker Hughes',\n",
       " 'Ball',\n",
       " 'Bank of America',\n",
       " 'Bath & Body Works',\n",
       " 'Baxter',\n",
       " 'Becton Dickinson',\n",
       " 'Berkley',\n",
       " 'Berkshire Hathaway',\n",
       " 'Best Buy',\n",
       " 'Bio-Rad',\n",
       " 'Bio-Techne',\n",
       " 'Biogen',\n",
       " 'BlackRock',\n",
       " 'BNY Mellon',\n",
       " 'Boeing',\n",
       " 'Booking Holdings',\n",
       " 'BorgWarner',\n",
       " 'Boston Properties',\n",
       " 'Boston Scientific',\n",
       " 'Bristol Myers Squibb',\n",
       " 'Broadcom',\n",
       " 'Broadridge',\n",
       " 'Brown & Brown',\n",
       " 'Brown–Forman',\n",
       " 'C.H. Robinson',\n",
       " 'Cadence',\n",
       " 'Caesars Entertainment',\n",
       " 'Camden',\n",
       " \"Campbell's\",\n",
       " 'Capital One',\n",
       " 'Cardinal Health',\n",
       " 'CarMax',\n",
       " 'Carnival',\n",
       " 'Carrier',\n",
       " 'Catalent',\n",
       " 'Caterpillar',\n",
       " 'Cboe',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'Celanese',\n",
       " 'Centene',\n",
       " 'CenterPoint Energy',\n",
       " 'Ceridian',\n",
       " 'Cerner',\n",
       " 'CF Industries',\n",
       " 'Charles River',\n",
       " 'Charles Schwab',\n",
       " 'Charter Communications',\n",
       " 'Chevron',\n",
       " 'Chipotle Mexican Grill',\n",
       " 'Chubb',\n",
       " 'Church & Dwight',\n",
       " 'Cigna',\n",
       " 'Cincinnati Financial',\n",
       " 'Cintas',\n",
       " 'Cisco',\n",
       " 'Citigroup',\n",
       " 'Citizens',\n",
       " 'Citrix',\n",
       " 'Clorox',\n",
       " 'CME Group',\n",
       " 'CMS Energy',\n",
       " 'Coca-Cola',\n",
       " 'Cognizant',\n",
       " 'Colgate-Palmolive',\n",
       " 'Comcast',\n",
       " 'Comerica',\n",
       " 'Conagra Brands',\n",
       " 'ConocoPhillips',\n",
       " 'Con Edison',\n",
       " 'Constellation Brands',\n",
       " 'Constellation Energy',\n",
       " 'CooperCompanies',\n",
       " 'Copart',\n",
       " 'Corning',\n",
       " 'Corteva',\n",
       " 'Costco',\n",
       " 'Coterra',\n",
       " 'Crown Castle',\n",
       " 'CSX',\n",
       " 'Cummins',\n",
       " 'CVS Health',\n",
       " 'D.R. Horton',\n",
       " 'Danaher',\n",
       " 'Darden',\n",
       " 'DaVita',\n",
       " 'Deere & Co.',\n",
       " 'Delta Air Lines',\n",
       " 'Dentsply Sirona',\n",
       " 'Devon',\n",
       " 'DexCom',\n",
       " 'Diamondback',\n",
       " 'Digital Realty',\n",
       " 'Discover',\n",
       " 'Dish',\n",
       " 'Disney',\n",
       " 'Dollar General',\n",
       " 'Dollar Tree',\n",
       " 'Dominion Energy',\n",
       " \"Domino's\",\n",
       " 'Dover',\n",
       " 'Dow',\n",
       " 'DTE',\n",
       " 'Duke Energy',\n",
       " 'Duke Realty',\n",
       " 'DuPont',\n",
       " 'DXC Technology',\n",
       " 'Eastman',\n",
       " 'Eaton',\n",
       " 'eBay',\n",
       " 'Ecolab',\n",
       " 'Edison International',\n",
       " 'Edwards Lifesciences',\n",
       " 'Electronic Arts',\n",
       " 'Emerson',\n",
       " 'Enphase',\n",
       " 'Entergy',\n",
       " 'EOG Resources',\n",
       " 'EPAM',\n",
       " 'Equifax',\n",
       " 'Equinix',\n",
       " 'Equity Residential',\n",
       " 'Essex',\n",
       " 'Estée Lauder Companies',\n",
       " 'Etsy',\n",
       " 'Everest',\n",
       " 'Evergy',\n",
       " 'Eversource',\n",
       " 'Exelon',\n",
       " 'Expedia Group',\n",
       " 'Expeditors',\n",
       " 'Extra Space Storage',\n",
       " 'ExxonMobil',\n",
       " 'F5',\n",
       " 'FactSet',\n",
       " 'Fastenal',\n",
       " 'Federal Realty',\n",
       " 'FedEx',\n",
       " 'Fifth Third Bank',\n",
       " 'First Republic',\n",
       " 'FirstEnergy',\n",
       " 'FIS',\n",
       " 'Fiserv',\n",
       " 'Fleetcor',\n",
       " 'FMC',\n",
       " 'Ford',\n",
       " 'Fortinet',\n",
       " 'Fortive',\n",
       " 'Fortune Brands',\n",
       " 'Fox Corporation (Class A)',\n",
       " 'Fox Corporation (Class B)',\n",
       " 'Franklin Templeton',\n",
       " 'Freeport-McMoRan',\n",
       " 'Gallagher',\n",
       " 'Garmin',\n",
       " 'Gartner',\n",
       " 'GE',\n",
       " 'Generac',\n",
       " 'General Dynamics',\n",
       " 'General Mills',\n",
       " 'Genuine Parts',\n",
       " 'Gilead',\n",
       " 'Globe Life',\n",
       " 'Global Payments',\n",
       " 'GM',\n",
       " 'Goldman Sachs',\n",
       " 'Grainger',\n",
       " 'Halliburton',\n",
       " 'Hartford (The)',\n",
       " 'Hasbro',\n",
       " 'HCA Healthcare',\n",
       " 'Healthpeak',\n",
       " 'Henry Schein',\n",
       " \"Hershey's\",\n",
       " 'Hess',\n",
       " 'Hewlett Packard Enterprise',\n",
       " 'Hilton',\n",
       " 'Hologic',\n",
       " 'Home Depot',\n",
       " 'Honeywell',\n",
       " 'Hormel',\n",
       " 'Host Hotels & Resorts',\n",
       " 'Howmet Aerospace',\n",
       " 'HP',\n",
       " 'Humana',\n",
       " 'Huntington Ingalls Industries',\n",
       " 'Huntington National Bank',\n",
       " 'IDEX',\n",
       " 'Idexx Laboratories',\n",
       " 'Illinois Tool Works',\n",
       " 'Illumina',\n",
       " 'Incyte',\n",
       " 'Ingersoll Rand',\n",
       " 'Intel',\n",
       " 'Intercontinental Exchange',\n",
       " 'IBM',\n",
       " 'International Paper',\n",
       " 'Interpublic Group',\n",
       " 'International Flavors & Fragrances',\n",
       " 'Intuit',\n",
       " 'Intuitive Surgical',\n",
       " 'Invesco',\n",
       " 'IPG Photonics',\n",
       " 'IQVIA',\n",
       " 'Iron Mountain',\n",
       " 'J.B. Hunt',\n",
       " 'Jack Henry & Associates',\n",
       " 'Jacobs',\n",
       " 'Johnson & Johnson',\n",
       " 'Johnson Controls',\n",
       " 'JPMorgan Chase',\n",
       " 'Juniper Networks',\n",
       " \"Kellogg's\",\n",
       " 'KeyCorp',\n",
       " 'Keysight',\n",
       " 'Kimberly-Clark',\n",
       " 'Kimco Realty',\n",
       " 'Kinder Morgan',\n",
       " 'KLA',\n",
       " 'Kraft Heinz',\n",
       " 'Kroger',\n",
       " 'L3Harris',\n",
       " 'LabCorp',\n",
       " 'Lam Research',\n",
       " 'Lamb Weston',\n",
       " 'Las Vegas Sands',\n",
       " 'Leidos',\n",
       " 'Lennar',\n",
       " 'Lilly',\n",
       " 'Lincoln Financial',\n",
       " 'Linde',\n",
       " 'Live Nation Entertainment',\n",
       " 'LKQ Corporation',\n",
       " 'Lockheed Martin',\n",
       " 'Loews Corporation',\n",
       " \"Lowe's\",\n",
       " 'Lumen',\n",
       " 'LyondellBasell',\n",
       " 'M&T Bank',\n",
       " 'Marathon Oil',\n",
       " 'Marathon Petroleum',\n",
       " 'MarketAxess',\n",
       " 'Marriott International',\n",
       " 'Marsh & McLennan',\n",
       " 'Martin Marietta',\n",
       " 'Masco',\n",
       " 'Mastercard',\n",
       " 'Match Group',\n",
       " 'McCormick',\n",
       " \"McDonald's\",\n",
       " 'McKesson',\n",
       " 'Medtronic',\n",
       " 'Merck',\n",
       " 'Meta',\n",
       " 'MetLife',\n",
       " 'Mettler Toledo',\n",
       " 'MGM Resorts',\n",
       " 'Microchip',\n",
       " 'Micron',\n",
       " 'Microsoft',\n",
       " 'Mid-America Apartments',\n",
       " 'Moderna',\n",
       " 'Mohawk Industries',\n",
       " 'Molina Healthcare',\n",
       " 'Molson Coors',\n",
       " 'Mondelez International',\n",
       " 'Monolithic Power Systems',\n",
       " 'Monster Beverage',\n",
       " \"Moody's\",\n",
       " 'Morgan Stanley',\n",
       " 'Mosaic',\n",
       " 'Motorola Solutions',\n",
       " 'MSCI',\n",
       " 'Nasdaq',\n",
       " 'NetApp',\n",
       " 'Netflix',\n",
       " 'Newell Brands',\n",
       " 'Newmont',\n",
       " 'News Corp (Class A)',\n",
       " 'News Corp (Class B)',\n",
       " 'NextEra Energy',\n",
       " 'Nielsen',\n",
       " 'Nike',\n",
       " 'NiSource',\n",
       " 'Nordson',\n",
       " 'Norfolk Southern',\n",
       " 'Northern Trust',\n",
       " 'Northrop Grumman',\n",
       " 'NortonLifeLock',\n",
       " 'Norwegian Cruise Line Holdings',\n",
       " 'NRG Energy',\n",
       " 'Nucor',\n",
       " 'Nvidia',\n",
       " 'NVR',\n",
       " 'NXP',\n",
       " \"O'Reilly Automotive\",\n",
       " 'Occidental Petroleum',\n",
       " 'Old Dominion',\n",
       " 'Omnicom Group',\n",
       " 'Oneok',\n",
       " 'Oracle',\n",
       " 'Organon',\n",
       " 'Otis',\n",
       " 'Paccar',\n",
       " 'Packaging Corporation of America',\n",
       " 'Paramount',\n",
       " 'Parker',\n",
       " 'Paychex',\n",
       " 'Paycom',\n",
       " 'PayPal',\n",
       " 'Penn National Gaming',\n",
       " 'Pentair',\n",
       " 'PepsiCo',\n",
       " 'PerkinElmer',\n",
       " 'Pfizer',\n",
       " 'Philip Morris International',\n",
       " 'Phillips 66',\n",
       " 'Pinnacle West',\n",
       " 'Pioneer Natural Resources',\n",
       " 'PNC Financial Services',\n",
       " 'Pool Corporation',\n",
       " 'PPG Industries',\n",
       " 'PPL',\n",
       " 'Principal',\n",
       " 'Procter & Gamble',\n",
       " 'Progressive',\n",
       " 'Prologis',\n",
       " 'Prudential',\n",
       " 'PSEG',\n",
       " 'PTC',\n",
       " 'Public Storage',\n",
       " 'PulteGroup',\n",
       " 'PVH',\n",
       " 'Qorvo',\n",
       " 'Quanta',\n",
       " 'Qualcomm',\n",
       " 'Quest Diagnostics',\n",
       " 'Ralph Lauren',\n",
       " 'Raymond James',\n",
       " 'Raytheon Technologies',\n",
       " 'Realty Income',\n",
       " 'Regency Centers',\n",
       " 'Regeneron',\n",
       " 'Regions',\n",
       " 'Republic Services',\n",
       " 'ResMed',\n",
       " 'Robert Half',\n",
       " 'Rockwell Automation',\n",
       " 'Rollins',\n",
       " 'Roper',\n",
       " 'Ross',\n",
       " 'Royal Caribbean Group',\n",
       " 'S&P Global',\n",
       " 'Salesforce',\n",
       " 'SBA Communications',\n",
       " 'Schlumberger',\n",
       " 'Seagate',\n",
       " 'Sealed Air',\n",
       " 'Sempra Energy',\n",
       " 'ServiceNow',\n",
       " 'Sherwin-Williams',\n",
       " 'Signature Bank',\n",
       " 'Simon',\n",
       " 'Skyworks',\n",
       " 'Smucker',\n",
       " 'Snap-on',\n",
       " 'SolarEdge',\n",
       " 'Southern Company',\n",
       " 'Southwest Airlines',\n",
       " 'Stanley Black & Decker',\n",
       " 'Starbucks',\n",
       " 'State Street',\n",
       " 'Steris',\n",
       " 'Stryker',\n",
       " 'SVB Financial',\n",
       " 'Synchrony',\n",
       " 'Synopsys',\n",
       " 'Sysco',\n",
       " 'T-Mobile',\n",
       " 'T. Rowe Price',\n",
       " 'Take-Two Interactive',\n",
       " 'Tapestry',\n",
       " 'Target',\n",
       " 'TE Connectivity',\n",
       " 'Teledyne',\n",
       " 'Teleflex',\n",
       " 'Teradyne',\n",
       " 'Tesla',\n",
       " 'Texas Instruments',\n",
       " 'Textron',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'TJX Companies',\n",
       " 'Tractor Supply',\n",
       " 'Trane Technologies',\n",
       " 'TransDigm',\n",
       " 'Travelers',\n",
       " 'Trimble',\n",
       " 'Truist',\n",
       " 'Twitter',\n",
       " 'Tyler Technologies',\n",
       " 'Tyson',\n",
       " 'U.S. Bank',\n",
       " 'UDR',\n",
       " 'Ulta Beauty',\n",
       " 'Under Armour (Class A)',\n",
       " 'Under Armour (Class C)',\n",
       " 'Union Pacific',\n",
       " 'United Airlines',\n",
       " 'UnitedHealth Group',\n",
       " 'United Parcel Service',\n",
       " 'United Rentals',\n",
       " 'Universal Health Services',\n",
       " 'Valero',\n",
       " 'Ventas',\n",
       " 'Verisign',\n",
       " 'Verisk',\n",
       " 'Verizon',\n",
       " 'Vertex',\n",
       " 'VF Corporation',\n",
       " 'Viatris',\n",
       " 'Visa',\n",
       " 'Vornado Realty Trust',\n",
       " 'Vulcan Materials',\n",
       " 'Wabtec',\n",
       " 'Walmart',\n",
       " 'Walgreens Boots Alliance',\n",
       " 'Warner Bros. Discovery',\n",
       " 'Waste Management',\n",
       " 'Waters',\n",
       " 'WEC Energy Group',\n",
       " 'Wells Fargo',\n",
       " 'Welltower',\n",
       " 'West Pharmaceutical Services',\n",
       " 'Western Digital',\n",
       " 'WestRock',\n",
       " 'Weyerhaeuser',\n",
       " 'Whirlpool',\n",
       " 'Williams',\n",
       " 'Willis Towers Watson',\n",
       " 'Wynn Resorts',\n",
       " 'Xcel Energy',\n",
       " 'Xylem',\n",
       " 'Yum! Brands',\n",
       " 'Zebra',\n",
       " 'Zimmer Biomet',\n",
       " 'Zions Bancorp',\n",
       " 'Zoetis']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = tick_comp_df[\"Security\"].to_list()\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1cc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_article(article, companies, df): #, tickers\n",
    "    if (article == \"NA\") | (article==\"\"):\n",
    "        tags = np.nan\n",
    "    else:\n",
    "        scores = process.extract(article, \n",
    "                                 companies,\n",
    "                                 scorer=fuzz.token_set_ratio, \n",
    "                                 limit=50)\n",
    "        comp_tags = [scores[i][0] for i in range(len(scores)) if scores[i][1]>90]\n",
    "        tags = list(df.loc[df.Security.isin(comp_tags), \"Symbol\"])\n",
    "        if len(tags) == 0:\n",
    "            tags = np.nan\n",
    "    return(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490ec923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_tags(old_df):\n",
    "    old_df = old_df.reset_index(drop=True)\n",
    "    new_df = pd.DataFrame(columns=old_df.columns)\n",
    "    for i in range(len(old_df)):\n",
    "        new_tags = old_df.tags[i]#.strip(\"][\").replace(\"'\",\"\").split(', ')\n",
    "        for t in new_tags:\n",
    "            new_df = new_df.append(old_df.iloc[i,:-1]).reset_index(drop=True)\n",
    "            new_df.tags.iloc[-1] = t\n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d83c15",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b0e18",
   "metadata": {},
   "source": [
    "### Load Roberta Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ce3ffa",
   "metadata": {
    "executionInfo": {
     "elapsed": 2436,
     "status": "ok",
     "timestamp": 1646868009935,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "d4ce3ffa"
   },
   "outputs": [],
   "source": [
    "roberta = pipeline(task='sentiment-analysis', \n",
    "                   model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\n",
    "                   return_all_scores=True,\n",
    "                   max_length=514, \n",
    "                   truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e7116",
   "metadata": {},
   "source": [
    " ### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc9868a",
   "metadata": {
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1646867679038,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "0bc9868a"
   },
   "outputs": [],
   "source": [
    "def summary_stats(score):\n",
    "    if len(score)== 0:\n",
    "        avg = np.nan\n",
    "        med = np.nan\n",
    "        min = np.nan\n",
    "        max = np.nan\n",
    "    else:\n",
    "        avg = round(np.mean(score),2)\n",
    "        med = round(np.median(score),2)\n",
    "        min = round(np.min(score),2)\n",
    "        max = round(np.max(score),2)\n",
    "    return(avg, med, min, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc9987",
   "metadata": {},
   "source": [
    "### Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b26ac37",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646867679039,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "9b26ac37"
   },
   "outputs": [],
   "source": [
    "# yahoo web scrape NLP\n",
    "def yahoo_nlp(urls, df):\n",
    "\n",
    "    df[\"pos_mean\"] = np.nan\n",
    "    df[\"pos_median\"] = np.nan\n",
    "    df[\"pos_min\"] = np.nan\n",
    "    df[\"pos_max\"] = np.nan\n",
    "\n",
    "    df[\"neg_mean\"] = np.nan\n",
    "    df[\"neg_median\"] = np.nan\n",
    "    df[\"neg_min\"] = np.nan\n",
    "    df[\"neg_max\"] = np.nan\n",
    "\n",
    "    df[\"neu_mean\"] = np.nan\n",
    "    df[\"neu_median\"] = np.nan\n",
    "    df[\"neu_min\"] = np.nan\n",
    "    df[\"neu_max\"] = np.nan\n",
    "    \n",
    "    df[\"net_mean\"] = np.nan\n",
    "    df[\"net_median\"] = np.nan\n",
    "    df[\"net_min\"] = np.nan\n",
    "    df[\"net_max\"] = np.nan\n",
    "    \n",
    "    score_df = pd.DataFrame()\n",
    "    sentence_df = pd.DataFrame()\n",
    "    tag_df = pd.DataFrame(columns=[\"tags\"])\n",
    "    \n",
    "    nf = \"Content is currently unavailable\"\n",
    "    \n",
    "    for i in range(len(urls)): #filter_urls\n",
    "        URL = urls.iloc[i] # filter_urls\n",
    "        page = requests.get(URL,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        if nf in soup.prettify():\n",
    "            text = \"NA\"\n",
    "            score_df = score_df.append(read_grades(text))\n",
    "            sentence_df = sentence_df.append(sentence_info(text))\n",
    "            tag_df.at[i, 'tags'] = tag_article(text,companies,tick_comp_df)\n",
    "        \n",
    "            continue\n",
    "        try:\n",
    "            try:\n",
    "                master = soup.find(id=\"Masterwrap\")\n",
    "                final = master.find(\"div\", class_=\"caas-body\")\n",
    "            except AttributeError:\n",
    "                master = soup.find(id=\"Masterwrap2Col\")\n",
    "                final = master.find(\"div\", class_=\"caas-body\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        text = re.sub('(<p>)', ' ', str(final))\n",
    "        text = re.sub('<[^>]+>', '', str(text))\n",
    "        sen_list = text.split(\". \")[:-2]\n",
    "        article = [\".\\n \".join(sen_list[:-2])][0] # remove author signature\n",
    "        score_df = score_df.append(read_grades(article))\n",
    "        sentence_df = sentence_df.append(sentence_info(article))\n",
    "        tag_df.at[i, 'tags'] = tag_article(article,companies,tick_comp_df)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        neu = []\n",
    "        net = []\n",
    "\n",
    "        for sen in sen_list:\n",
    "            try:\n",
    "                output = roberta(sen)\n",
    "            except IndexError:\n",
    "                output = roberta(sen[0:514])\n",
    "            neg.append(output[0][0]['score'])\n",
    "            neu.append(output[0][1]['score'])\n",
    "            pos.append(output[0][2]['score'])\n",
    "            net.append(pos[-1] - neg[-1])\n",
    "        \n",
    "        df.pos_mean.iloc[i], df.pos_median.iloc[i], df.pos_min.iloc[i], df.pos_max.iloc[i] = summary_stats(pos)\n",
    "        df.neg_mean.iloc[i], df.neg_median.iloc[i], df.neg_min.iloc[i], df.neg_max.iloc[i] = summary_stats(neg)\n",
    "        df.neu_mean.iloc[i], df.neu_median.iloc[i], df.neu_min.iloc[i], df.neu_max.iloc[i] = summary_stats(neu)\n",
    "        df.net_mean.iloc[i], df.net_median.iloc[i], df.net_min.iloc[i], df.net_max.iloc[i] = summary_stats(net)\n",
    "    \n",
    "    score_df.index = df.index\n",
    "    sentence_df.index = df.index\n",
    "    tag_df.index = df.index\n",
    "    df = pd.concat([df,score_df,sentence_df,tag_df],axis=1)\n",
    "    df = df.dropna()\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a114554",
   "metadata": {},
   "source": [
    "### MarketWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7687c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1646867679176,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "8e7687c2"
   },
   "outputs": [],
   "source": [
    "# marketwatch web scrape NLP\n",
    "def mwatch_nlp(urls, df):\n",
    "    \n",
    "    df[\"pos_mean\"] = np.nan\n",
    "    df[\"pos_median\"] = np.nan\n",
    "    df[\"pos_min\"] = np.nan\n",
    "    df[\"pos_max\"] = np.nan\n",
    "\n",
    "    df[\"neg_mean\"] = np.nan\n",
    "    df[\"neg_median\"] = np.nan\n",
    "    df[\"neg_min\"] = np.nan\n",
    "    df[\"neg_max\"] = np.nan\n",
    "\n",
    "    df[\"neu_mean\"] = np.nan\n",
    "    df[\"neu_median\"] = np.nan\n",
    "    df[\"neu_min\"] = np.nan\n",
    "    df[\"neu_max\"] = np.nan\n",
    "    \n",
    "    df[\"net_mean\"] = np.nan\n",
    "    df[\"net_median\"] = np.nan\n",
    "    df[\"net_min\"] = np.nan\n",
    "    df[\"net_max\"] = np.nan\n",
    "    \n",
    "    score_df = pd.DataFrame()\n",
    "    sentence_df = pd.DataFrame()\n",
    "    tag_df = pd.DataFrame(columns=[\"tags\"])\n",
    "    \n",
    "    nf = \"Story not found\"\n",
    "    \n",
    "    for i in range(len(urls)): #filter_urls\n",
    "        URL = urls.iloc[i] # filter_urls\n",
    "        page = requests.get(URL,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        if nf in soup.prettify():\n",
    "            text = \"NA\"\n",
    "            score_df = score_df.append(read_grades(text))\n",
    "            sentence_df = sentence_df.append(sentence_info(text))\n",
    "            tag_df.at[i, 'tags'] = tag_article(text,companies,tick_comp_df)\n",
    "            continue\n",
    "        try:\n",
    "            master = soup.find(id=\"maincontent\")\n",
    "            final = master.find(\"div\", class_=\"article__body article-wrap at16-col16 barrons-article-wrap\")\n",
    "            text = final.text.strip()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        sen_list = text.split(\".\")\n",
    "        article = [\".\\n \".join(sen_list)][0]\n",
    "        score_df = score_df.append(read_grades(article))\n",
    "        sentence_df = sentence_df.append(sentence_info(article))\n",
    "        tag_df.at[i, 'tags'] = tag_article(article,companies,tick_comp_df)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        neu = []\n",
    "        net = []\n",
    "\n",
    "        for sen in sen_list:\n",
    "            try:\n",
    "                output = roberta(sen)\n",
    "            except IndexError:\n",
    "                output = roberta(sen[0:514])\n",
    "            neg.append(output[0][0]['score'])\n",
    "            neu.append(output[0][1]['score'])\n",
    "            pos.append(output[0][2]['score'])\n",
    "            net.append(pos[-1] - neg[-1])\n",
    "\n",
    "        df.pos_mean.iloc[i], df.pos_median.iloc[i], df.pos_min.iloc[i], df.pos_max.iloc[i] = summary_stats(pos)\n",
    "        df.neg_mean.iloc[i], df.neg_median.iloc[i], df.neg_min.iloc[i], df.neg_max.iloc[i] = summary_stats(neg)\n",
    "        df.neu_mean.iloc[i], df.neu_median.iloc[i], df.neu_min.iloc[i], df.neu_max.iloc[i] = summary_stats(neu)\n",
    "        df.net_mean.iloc[i], df.net_median.iloc[i], df.net_min.iloc[i], df.net_max.iloc[i] = summary_stats(net)\n",
    "    \n",
    "    score_df.index = df.index\n",
    "    sentence_df.index = df.index\n",
    "    tag_df.index = df.index\n",
    "    df = pd.concat([df,score_df,sentence_df,tag_df],axis=1)\n",
    "    df = df.dropna()\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e13709",
   "metadata": {},
   "source": [
    "### PR Newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70adfe37",
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1646867679322,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "70adfe37"
   },
   "outputs": [],
   "source": [
    "# prnewswire web scrape NLP\n",
    "def prnw_nlp(urls, df):\n",
    "    \n",
    "    df[\"pos_mean\"] = np.nan\n",
    "    df[\"pos_median\"] = np.nan\n",
    "    df[\"pos_min\"] = np.nan\n",
    "    df[\"pos_max\"] = np.nan\n",
    "\n",
    "    df[\"neg_mean\"] = np.nan\n",
    "    df[\"neg_median\"] = np.nan\n",
    "    df[\"neg_min\"] = np.nan\n",
    "    df[\"neg_max\"] = np.nan\n",
    "\n",
    "    df[\"neu_mean\"] = np.nan\n",
    "    df[\"neu_median\"] = np.nan\n",
    "    df[\"neu_min\"] = np.nan\n",
    "    df[\"neu_max\"] = np.nan\n",
    "    \n",
    "    df[\"net_mean\"] = np.nan\n",
    "    df[\"net_median\"] = np.nan\n",
    "    df[\"net_min\"] = np.nan\n",
    "    df[\"net_max\"] = np.nan\n",
    "    \n",
    "    sentence_df = pd.DataFrame()\n",
    "    score_df = pd.DataFrame()\n",
    "    tag_df = pd.DataFrame(columns=[\"tags\"])\n",
    "    \n",
    "    nf = \"Content is currently unavailable\"\n",
    "    \n",
    "    for i in range(len(urls)): #filter_urls\n",
    "        URL = urls.iloc[i] # filter_urls\n",
    "        page = requests.get(URL,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        if nf in soup.prettify():\n",
    "            text = \"NA\"\n",
    "            score_df = score_df.append(read_grades(text))\n",
    "            sentence_df = sentence_df.append(sentence_info(text))\n",
    "            tag_df.at[i, 'tags'] = tag_article(text,companies,tick_comp_df)\n",
    "            continue\n",
    "        try:\n",
    "            master = soup.find(id=\"main\")\n",
    "            final = master.find_all(\"div\", class_=\"col-sm-10 col-sm-offset-1\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        try:\n",
    "            paragraphs = []\n",
    "            for wrapper in final:\n",
    "                paragraphs.append(wrapper.text.strip())\n",
    "                text = [\" \".join(paragraphs)][0]\n",
    "        except:\n",
    "            pass\n",
    "        sen_list = text.split(\". \")\n",
    "        article = [\".\\n \".join(sen_list)][0]\n",
    "        score_df = score_df.append(read_grades(article))\n",
    "        sentence_df = sentence_df.append(sentence_info(article))\n",
    "        tag_df.at[i, 'tags'] = tag_article(article,companies,tick_comp_df)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        neu = []\n",
    "        net = []\n",
    "\n",
    "        for sen in sen_list:\n",
    "            try:\n",
    "                output = roberta(sen)\n",
    "            except IndexError:\n",
    "                output = roberta(sen[0:514])\n",
    "            neg.append(output[0][0]['score'])\n",
    "            neu.append(output[0][1]['score'])\n",
    "            pos.append(output[0][2]['score'])\n",
    "            net.append(pos[-1] - neg[-1])\n",
    "        df.pos_mean.iloc[i], df.pos_median.iloc[i], df.pos_min.iloc[i], df.pos_max.iloc[i] = summary_stats(pos)\n",
    "        df.neg_mean.iloc[i], df.neg_median.iloc[i], df.neg_min.iloc[i], df.neg_max.iloc[i] = summary_stats(neg)\n",
    "        df.neu_mean.iloc[i], df.neu_median.iloc[i], df.neu_min.iloc[i], df.neu_max.iloc[i] = summary_stats(neu)\n",
    "        df.net_mean.iloc[i], df.net_median.iloc[i], df.net_min.iloc[i], df.net_max.iloc[i] = summary_stats(net)\n",
    "    \n",
    "    score_df.index = df.index\n",
    "    sentence_df.index = df.index\n",
    "    tag_df.index = df.index\n",
    "    df = pd.concat([df,score_df,sentence_df,tag_df],axis=1)\n",
    "    df = df.dropna()\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ade8b",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6740d292",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646867679323,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "6740d292"
   },
   "outputs": [],
   "source": [
    "# append yahoo, marketwatch, and prnewswire together for entire month dataset\n",
    "def append_df(df1,df2,df3):\n",
    "    df = df1.append([df2,df3])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02916264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/TyPainter1/Desktop/Masters/spring-2022/capstone/00-data/gdelt_data/2021/gdelt_apr2021.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85e4f752",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 7457,
     "status": "error",
     "timestamp": 1646868023711,
     "user": {
      "displayName": "Ty Painter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04234853017868576860"
     },
     "user_tz": 360
    },
    "id": "85e4f752",
    "outputId": "d278ed94-ace6-4ae1-fb62-f2b20fef439b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_paths loaded\n",
      "/Users/TyPainter1/Desktop/Masters/spring-2022/capstone/00-data/gdelt_data/2021/gdelt_apr2021.csv\n",
      "filter websites\n",
      "URL\n",
      "mwatch NLP\n",
      "prnw NLP\n",
      "yahoo NLP\n",
      "Append\n",
      "Row tags\n",
      "Completed in 0.95 minutes\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "file_paths = load_data()\n",
    "print(\"file_paths loaded\")\n",
    "for path in file_paths[0:1]:\n",
    "    print(path)\n",
    "    m_df, p_df, y_df = filter_websites(path)\n",
    "    print(\"filter websites\")\n",
    "    m_df = m_df[0:10]\n",
    "    p_df = p_df[0:5]\n",
    "    y_df = y_df[0:5]\n",
    "    \n",
    "    m_url = m_df.url\n",
    "    p_url = p_df.url\n",
    "    y_url = y_df.url\n",
    "    print(\"URL\")\n",
    "    \n",
    "    mwatch_df = mwatch_nlp(m_url, m_df)\n",
    "    print(\"mwatch NLP\")\n",
    "    prnw_df = prnw_nlp(p_url, p_df)\n",
    "    print(\"prnw NLP\")\n",
    "    yahoo_df = yahoo_nlp(y_url, y_df)\n",
    "    print(\"yahoo NLP\")\n",
    "    \n",
    "    app_df = append_df(yahoo_df,mwatch_df, prnw_df)\n",
    "    print(\"Append\")\n",
    "    \n",
    "    month_df = row_tags(app_df)\n",
    "    print(\"Row tags\")\n",
    "    \n",
    "    year_number = str(month_df.year.unique().item())\n",
    "    month_number = str(month_df.month.unique().item())\n",
    "    datetime_object = datetime.datetime.strptime(month_number, \"%m\")\n",
    "    month_name = datetime_object.strftime(\"%b\").lower()\n",
    "    file_name = 'nlp_'+month_name+str(year_number)+'.csv'\n",
    "    month_df.to_csv(file_name,\n",
    "                   index=False)\n",
    "    \n",
    "toc = time.perf_counter()\n",
    "print(f\"Completed in {(toc - tic)/60:0.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5be999fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting line_profiler\n",
      "  Downloading line_profiler-3.5.1-cp38-cp38-macosx_10_9_x86_64.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: line-profiler\n",
      "Successfully installed line-profiler-3.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67645bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    https://www.marketwatch.com/story/biden-seeks-...\n",
       "51    https://www.marketwatch.com/story/marathon-oil...\n",
       "59    https://www.marketwatch.com/story/paul-simon-s...\n",
       "61    https://www.marketwatch.com/story/netflix-fork...\n",
       "66    https://www.marketwatch.com/story/south-koreas...\n",
       "84    https://www.marketwatch.com/story/chauvin-told...\n",
       "88    https://www.marketwatch.com/story/pentagon-rel...\n",
       "94    https://www.marketwatch.com/story/u-s-alarmed-...\n",
       "96    https://www.marketwatch.com/story/sarah-palin-...\n",
       "99    https://www.marketwatch.com/story/myanmar-coul...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07958f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>website</th>\n",
       "      <th>url</th>\n",
       "      <th>pos_mean</th>\n",
       "      <th>pos_median</th>\n",
       "      <th>pos_min</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>neg_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_min</th>\n",
       "      <th>neg_max</th>\n",
       "      <th>neu_mean</th>\n",
       "      <th>neu_median</th>\n",
       "      <th>neu_min</th>\n",
       "      <th>neu_max</th>\n",
       "      <th>net_mean</th>\n",
       "      <th>net_median</th>\n",
       "      <th>net_min</th>\n",
       "      <th>net_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/biden-seeks-...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/marathon-oil...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/paul-simon-s...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/netflix-fork...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/south-koreas...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/chauvin-told...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/pentagon-rel...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/u-s-alarmed-...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/sarah-palin-...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>https://www.marketwatch.com/story/myanmar-coul...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day          website  \\\n",
       "50  2021      4    1  marketwatch.com   \n",
       "51  2021      4    1  marketwatch.com   \n",
       "59  2021      4    1  marketwatch.com   \n",
       "61  2021      4    1  marketwatch.com   \n",
       "66  2021      4    1  marketwatch.com   \n",
       "84  2021      4    1  marketwatch.com   \n",
       "88  2021      4    1  marketwatch.com   \n",
       "94  2021      4    1  marketwatch.com   \n",
       "96  2021      4    1  marketwatch.com   \n",
       "99  2021      4    1  marketwatch.com   \n",
       "\n",
       "                                                  url  pos_mean  pos_median  \\\n",
       "50  https://www.marketwatch.com/story/biden-seeks-...      0.24         0.0   \n",
       "51  https://www.marketwatch.com/story/marathon-oil...      0.00         0.0   \n",
       "59  https://www.marketwatch.com/story/paul-simon-s...      0.17         0.0   \n",
       "61  https://www.marketwatch.com/story/netflix-fork...      0.22         0.0   \n",
       "66  https://www.marketwatch.com/story/south-koreas...      0.57         1.0   \n",
       "84  https://www.marketwatch.com/story/chauvin-told...      0.00         0.0   \n",
       "88  https://www.marketwatch.com/story/pentagon-rel...      0.17         0.0   \n",
       "94  https://www.marketwatch.com/story/u-s-alarmed-...      0.04         0.0   \n",
       "96  https://www.marketwatch.com/story/sarah-palin-...      0.08         0.0   \n",
       "99  https://www.marketwatch.com/story/myanmar-coul...      0.05         0.0   \n",
       "\n",
       "    pos_min  pos_max  neg_mean  ...  neg_min  neg_max  neu_mean  neu_median  \\\n",
       "50      0.0     1.00      0.00  ...      0.0     0.00      0.76         1.0   \n",
       "51      0.0     0.00      0.09  ...      0.0     1.00      0.91         1.0   \n",
       "59      0.0     1.00      0.00  ...      0.0     0.00      0.83         1.0   \n",
       "61      0.0     1.00      0.00  ...      0.0     0.00      0.78         1.0   \n",
       "66      0.0     1.00      0.01  ...      0.0     0.16      0.42         0.0   \n",
       "84      0.0     0.02      0.07  ...      0.0     0.69      0.93         1.0   \n",
       "88      0.0     1.00      0.10  ...      0.0     1.00      0.73         1.0   \n",
       "94      0.0     0.90      0.20  ...      0.0     0.99      0.76         1.0   \n",
       "96      0.0     0.85      0.00  ...      0.0     0.00      0.92         1.0   \n",
       "99      0.0     1.00      0.24  ...      0.0     1.00      0.71         1.0   \n",
       "\n",
       "    neu_min  neu_max  net_mean  net_median  net_min  net_max  \n",
       "50     0.00      1.0      0.24        -0.0    -0.00     1.00  \n",
       "51     0.00      1.0     -0.09        -0.0    -1.00     0.00  \n",
       "59     0.00      1.0      0.17        -0.0    -0.00     1.00  \n",
       "61     0.00      1.0      0.22         0.0    -0.00     1.00  \n",
       "66     0.00      1.0      0.56         1.0    -0.16     1.00  \n",
       "84     0.31      1.0     -0.06        -0.0    -0.69     0.00  \n",
       "88     0.00      1.0      0.07        -0.0    -1.00     1.00  \n",
       "94     0.00      1.0     -0.16        -0.0    -0.98     0.89  \n",
       "96     0.15      1.0      0.08        -0.0    -0.00     0.84  \n",
       "99     0.00      1.0     -0.19        -0.0    -1.00     1.00  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee41c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TyPainter1/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "%lprun -f mwatch_nlp mwatch_nlp(m_url, m_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nlp_sentiment_scores.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
